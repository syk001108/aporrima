# Hadoop

# **Quick Install Command Summary**

- Distributed environment
    - Meaning each different instance (Not same instance NameNode and DataNode, it just same OS)

ğŸŸª**NameNode**

```python
sudo apt-get install git
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/step1to3.sh [NameNode ip Address] [DataNode ip Address]
```

passwd : `hadoop`

ğŸŸ©**DataNode**

```python
sudo apt-get install git
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/step1to3.sh [NameNode ip Address] [DataNode ip Address]
```

passwd : `hadoop`

ğŸŸª**NameNode**

```python
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/connect.sh
```

You should `enter` 3 times, input `yes`, and input passwd `hadoop`

If you have tested the ssh connection(ex. `ssh hadoop@hdw1`), input `exit` and return to the existing window. And repeat.

ğŸŸ©**DataNode**

```python
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/connect.sh
```

You should `enter` 3 times, input `yes`, and input passwd `hadoop`

If you have tested the ssh connection (ex. `ssh hadoop@hdn`), input `exit` and return to the existing window. And repeat**.**

ğŸŸª**NameNode**

```python
./aporrima/hadoop/installHadoop.sh
echo $HADOOP_HOME
. ~/.bashrc
./aporrima/hadoop/setHadoop.sh
jps
```

# Environment Setup

## Step 1 - Environmental Preparation

- ubuntu 22.04
- apt update
- OpenJDK 8
- OpenSSH
    - SSH Server Configuration Settings
        - `/etc/ssh/sshd_config`
        - To access without writing a password
- net-tools

### â—C**aution**â—

1. Proceed fromÂ **an account whereÂ `sudo`Â command is available**
2. Run on bothÂ **NameNode and DataNode**

### ğŸ”¸Script

[install.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/install.sh)

### â–¶Execute

ğŸ”¹Input (NameNode & DataNode)

```python
sudo apt-get install git
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/install.sh
```

## Step 2 -Â **Register domain to host**

For smooth connection of NameNode and DataNode.

- Write an ip address in a fileÂ `/etc/hosts`
    - NameNode
        - `xxx.xxx.xxx.xxx hdn`
    - DataNode
        - `xxx.xxx.xxx.xxx hdw1`
        - `xxx.xxx.xxx.xxx hdw2`
        - â€¦

### â—C**aution**â—

1. Proceed fromÂ **an account whereÂ `sudo`Â command is available**
2. Run on bothÂ **NameNode and DataNode**

### ğŸ”¸Script

[hostset.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/hostset.sh)

### â–¶Execute

ğŸ”¹Input

```python
./aporrima/hadoop/hostset.sh (NameNode's ip address) (DataNode's ip address) (DataNode's ip address)...
```

ğŸ”¹Example (NameNode & DataNode)

```python
./aporrima/hadoop/hostset.sh 10.0.20.157 10.0.20.181 10.0.20.182 10.0.20.183
```

## Step 3 - Create a Hadoop account

Create Hadoop-only user accounts to distinguish Hadoop processes from other services running on the same computer

- User name
    - `hadoop`
- User passwd
    - `hadoop`
- User home directory
    - `/home/hadoop`

### â—C**aution**â—

1. Proceed fromÂ **an account whereÂ `sudo`Â command is available**
2. When the password input window appears,
    1. InputÂ `hadoop`
3. Run on bothÂ **NameNode and DataNode**
4. **Must not have**Â a Hadoop account
    - If you have an account,Â `sudo userdel -rf hadoop`

### ğŸ”¸Script

[makeUser.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/makeUser.sh)

### â–¶Execute

ğŸ”¹Input (NameNode & DataNode)

```python
./aporrima/hadoop/makeUser.sh
cd
```

- Password : `hadoop`
- Can enterÂ `/home/hadoop`Â folder toÂ `cd`Â command

## Step 4 - Nodes set up connection without password

Access without SSH password with public key authentication

### â—C**aution**â—

1. Run on bothÂ **NameNode and DataNode**
2. When the password input window appears,
    1. InputÂ `hadoop`
3. Recommendation for confirmation of connection afterwards (All ip address / excluding personal ip address)
    
    ex.Â `ssh hadoop@hdn`
    

### ğŸ”¸Script

[connect.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/connect.sh)

### â–¶Execute

ğŸ”¹Input

```python
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/connect.sh
```

ğŸ”¹Example (NameNode)

```python
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/connect.sh
```

You should `enter` 3 times, input `yes`, and input passwd `hadoop`

```python
ssh hadoop@hdw1
ssh hadoop@hdw2
ssh hadoop@hdw3
```

- Check password-free access

If you have tested the ssh connection, input `exit` and return to the existing window. And repeat**.**

ğŸ”¹Example (DataNode - hd1)

```python
git clone https://github.com/psy337337/aporrima.git
./aporrima/hadoop/connect.sh
```

You should `enter` 3 times, input `yes`, and input passwd `hadoop`

```python
ssh hadoop@hdw1
ssh hadoop@hdw2
ssh hadoop@hdw3
```

- Check password-free access

If you have tested the ssh connection, input `exit` and return to the existing window. And repeat**.**

## Step 5 - Install Hadoop

- hadoop 3.3.4
- Setting environment variables
    - `/home/hadoop/.bashrc`
    - bashrc.txt

### â—C**aution**â—

1. RunÂ **only on NameNode**
2. InputÂ `echo $HADOOP_HOME`Â after execution
    - If there is no output value
        - InputÂ `. ~/.bashrc`Â orÂ `source ~/.bashrc`

### ğŸ”¸Script

[installHadoop.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/installHadoop.sh)

### â–¶Execute

ğŸ”¹Input

```python
./aporrima/hadoop/installHadoop.sh
. ~/.bashrc
```

ğŸ”¹Example (NameNode)

```python
./aporrima/hadoop/installHadoop.sh
echo $HADOOP_HOME
. ~/.bashrc
```

- Check environment variables are applied

## Step 6 - Hadoop Setting & Start

Setting to run Hadoop and running Hadoop

- Enter DataNode inÂ `$HADOOP_HOME/etc/hadoop/workers`
    - `hdw1`
    - `hdw2`
    - â€¦
- SettingÂ `JAVA_HOME`
    - `$HADOOP_HOME/etc/hadoop/hadoop-env.sh`
- `core-site.xml`
    - [core-site.txt](https://github.com/psy337337/aporrima/blob/main/hadoop/core-site.txt)
    - Common environment settings for hdfs and map reduce
    - Setting the ip address for file system metadata-related operations
        - Setting address to NameNode ip address
- `hdfs-site.xml`
    - [hdfs-site.txt](https://github.com/psy337337/aporrima/blob/main/hadoop/hdfs-site.txt)
    - Configuration settings for use by hdfs
- `mapred-site.xml`
    - [mapred-site.txt](https://github.com/psy337337/aporrima/blob/main/hadoop/mapred-site.txt)
    - Configuration settings for use by map reduce
- `yarn-site.xml`
    - [yarn-site.txt](https://github.com/psy337337/aporrima/blob/main/hadoop/yarn-site.txt)
    - Configuration settings for use by yarn
    - Set ip address inÂ `yarn.resourcemanager.address`
        - Setting address to NameNode ip address
    - Set ip address inÂ `yarn.router.webapp.address`
        - Setting address to NameNode ip address

### â—C**aution**â—

1. RunÂ **only on NameNode**
2. If you want to shut down/restart Hadoop after running
    - Hadoop shut down
        - `$HADOOP_HOME/sbin/stop-all.sh`
    - Hadoop restart
        - `$HADOOP_HOME/sbin/start-all.sh`

### ğŸ”¸Script

[setHadoop.sh](https://github.com/psy337337/aporrima/blob/main/hadoop/setHadoop.sh)

### â–¶Execute

ğŸ”¹Input

```python
./aporrima/hadoop/setHadoop.sh
```

ğŸ”¹Example (NameNode)

```python
./aporrima/hadoop/setHadoop.sh
jps
```

- `jps`Â command allows you to check the running process
    - NameNode
        - `SecondaryNameNode`
        - `WebAppProxyServer`
        - `NameNode`
        - `ResourceManager`
    - DataNode
        - `DataNode`
        - `NodeManager`
